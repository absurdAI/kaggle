{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b31d4d42",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-21T13:26:12.973453Z",
     "iopub.status.busy": "2024-08-21T13:26:12.972484Z",
     "iopub.status.idle": "2024-08-21T13:26:13.753072Z",
     "shell.execute_reply": "2024-08-21T13:26:13.751682Z"
    },
    "papermill": {
     "duration": 0.789029,
     "end_time": "2024-08-21T13:26:13.756053",
     "exception": false,
     "start_time": "2024-08-21T13:26:12.967024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/spaceship-titanic/sample_submission.csv\n",
      "/kaggle/input/spaceship-titanic/train.csv\n",
      "/kaggle/input/spaceship-titanic/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5852cf72",
   "metadata": {
    "papermill": {
     "duration": 0.003182,
     "end_time": "2024-08-21T13:26:13.763111",
     "exception": false,
     "start_time": "2024-08-21T13:26:13.759929",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Exploring dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59238f54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T13:26:13.771501Z",
     "iopub.status.busy": "2024-08-21T13:26:13.770995Z",
     "iopub.status.idle": "2024-08-21T13:26:13.914499Z",
     "shell.execute_reply": "2024-08-21T13:26:13.913289Z"
    },
    "papermill": {
     "duration": 0.151602,
     "end_time": "2024-08-21T13:26:13.917986",
     "exception": false,
     "start_time": "2024-08-21T13:26:13.766384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DataFrame:\n",
      "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
      "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
      "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
      "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
      "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
      "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
      "\n",
      "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
      "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
      "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
      "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
      "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
      "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
      "\n",
      "   Transported  \n",
      "0        False  \n",
      "1         True  \n",
      "2        False  \n",
      "3        False  \n",
      "4         True  \n",
      "\n",
      "Test DataFrame:\n",
      "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
      "0     0013_01      Earth      True  G/3/S  TRAPPIST-1e  27.0  False   \n",
      "1     0018_01      Earth     False  F/4/S  TRAPPIST-1e  19.0  False   \n",
      "2     0019_01     Europa      True  C/0/S  55 Cancri e  31.0  False   \n",
      "3     0021_01     Europa     False  C/1/S  TRAPPIST-1e  38.0  False   \n",
      "4     0023_01      Earth     False  F/5/S  TRAPPIST-1e  20.0  False   \n",
      "\n",
      "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck              Name  \n",
      "0          0.0        0.0           0.0     0.0     0.0   Nelly Carsoning  \n",
      "1          0.0        9.0           0.0  2823.0     0.0    Lerome Peckers  \n",
      "2          0.0        0.0           0.0     0.0     0.0   Sabih Unhearfus  \n",
      "3          0.0     6652.0           0.0   181.0   585.0  Meratz Caltilter  \n",
      "4         10.0        0.0         635.0     0.0     0.0   Brence Harperez  \n",
      "\n",
      "Training DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   8693 non-null   object \n",
      " 1   HomePlanet    8492 non-null   object \n",
      " 2   CryoSleep     8476 non-null   object \n",
      " 3   Cabin         8494 non-null   object \n",
      " 4   Destination   8511 non-null   object \n",
      " 5   Age           8514 non-null   float64\n",
      " 6   VIP           8490 non-null   object \n",
      " 7   RoomService   8512 non-null   float64\n",
      " 8   FoodCourt     8510 non-null   float64\n",
      " 9   ShoppingMall  8485 non-null   float64\n",
      " 10  Spa           8510 non-null   float64\n",
      " 11  VRDeck        8505 non-null   float64\n",
      " 12  Name          8493 non-null   object \n",
      " 13  Transported   8693 non-null   bool   \n",
      "dtypes: bool(1), float64(6), object(7)\n",
      "memory usage: 891.5+ KB\n",
      "None\n",
      "\n",
      "Training DataFrame Description:\n",
      "               Age   RoomService     FoodCourt  ShoppingMall           Spa  \\\n",
      "count  8514.000000   8512.000000   8510.000000   8485.000000   8510.000000   \n",
      "mean     28.827930    224.687617    458.077203    173.729169    311.138778   \n",
      "std      14.489021    666.717663   1611.489240    604.696458   1136.705535   \n",
      "min       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%      19.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%      27.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%      38.000000     47.000000     76.000000     27.000000     59.000000   \n",
      "max      79.000000  14327.000000  29813.000000  23492.000000  22408.000000   \n",
      "\n",
      "             VRDeck  \n",
      "count   8505.000000  \n",
      "mean     304.854791  \n",
      "std     1145.717189  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        0.000000  \n",
      "75%       46.000000  \n",
      "max    24133.000000  \n",
      "\n",
      "Missing Values in Training DataFrame:\n",
      "PassengerId       0\n",
      "HomePlanet      201\n",
      "CryoSleep       217\n",
      "Cabin           199\n",
      "Destination     182\n",
      "Age             179\n",
      "VIP             203\n",
      "RoomService     181\n",
      "FoodCourt       183\n",
      "ShoppingMall    208\n",
      "Spa             183\n",
      "VRDeck          188\n",
      "Name            200\n",
      "Transported       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the train and test datasets into Pandas dataframes\n",
    "train_df = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')\n",
    "\n",
    "# Explore the first few rows of the train dataset\n",
    "print(\"Training DataFrame:\")\n",
    "print(train_df.head())\n",
    "\n",
    "# Explore the first few rows of the test dataset\n",
    "print(\"\\nTest DataFrame:\")\n",
    "print(test_df.head())\n",
    "\n",
    "# Get a summary of the train dataset\n",
    "print(\"\\nTraining DataFrame Info:\")\n",
    "print(train_df.info())\n",
    "\n",
    "# Get basic statistics for the numerical features in the train dataset\n",
    "print(\"\\nTraining DataFrame Description:\")\n",
    "print(train_df.describe())\n",
    "\n",
    "# Check for missing values in the training data\n",
    "print(\"\\nMissing Values in Training DataFrame:\")\n",
    "print(train_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7445fdd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T13:26:13.927084Z",
     "iopub.status.busy": "2024-08-21T13:26:13.926707Z",
     "iopub.status.idle": "2024-08-21T13:26:16.687307Z",
     "shell.execute_reply": "2024-08-21T13:26:16.685853Z"
    },
    "papermill": {
     "duration": 2.768207,
     "end_time": "2024-08-21T13:26:16.689982",
     "exception": false,
     "start_time": "2024-08-21T13:26:13.921775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Step 1: Load the train and test datasets\n",
    "train_df = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')\n",
    "\n",
    "# Remove the 'Transported' column from the train dataset before combining\n",
    "train_df_no_target = train_df.drop(columns=['Transported'])\n",
    "\n",
    "# Combine the train and test datasets\n",
    "combined_df = pd.concat([train_df_no_target, test_df], ignore_index=True)\n",
    "\n",
    "# Step 2: KNN Imputation\n",
    "# Initialize the KNN Imputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Apply KNN Imputation only on numeric columns\n",
    "numeric_cols = combined_df.select_dtypes(include=[np.number]).columns\n",
    "imputed_data = imputer.fit_transform(combined_df[numeric_cols])\n",
    "\n",
    "# Convert the imputed data back into the combined DataFrame\n",
    "combined_df[numeric_cols] = pd.DataFrame(imputed_data, columns=numeric_cols)\n",
    "\n",
    "# Step 3: Feature Engineering - Example of splitting the 'Cabin' column\n",
    "# Splitting the 'Cabin' column into 'Deck', 'Cabin_Number', and 'Side'\n",
    "combined_df[['Deck', 'Cabin_Number', 'Side']] = combined_df['Cabin'].str.split('/', expand=True)\n",
    "\n",
    "# Drop the original 'Cabin' column as it's now split\n",
    "combined_df.drop(columns=['Cabin'], inplace=True)\n",
    "\n",
    "# Continue with other feature engineering steps here...\n",
    "# For example: One-hot encoding for categorical columns, creating new features, etc.\n",
    "\n",
    "# NOTE: Do NOT split the dataset yet! Continue with any other feature engineering as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88096cf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T13:26:16.699602Z",
     "iopub.status.busy": "2024-08-21T13:26:16.698589Z",
     "iopub.status.idle": "2024-08-21T13:26:16.712631Z",
     "shell.execute_reply": "2024-08-21T13:26:16.711513Z"
    },
    "papermill": {
     "duration": 0.021083,
     "end_time": "2024-08-21T13:26:16.714857",
     "exception": false,
     "start_time": "2024-08-21T13:26:16.693774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in the combined dataset after KNN Imputation and feature engineering:\n",
      "PassengerId       0\n",
      "HomePlanet      288\n",
      "CryoSleep       310\n",
      "Destination     274\n",
      "Age               0\n",
      "VIP             296\n",
      "RoomService       0\n",
      "FoodCourt         0\n",
      "ShoppingMall      0\n",
      "Spa               0\n",
      "VRDeck            0\n",
      "Name            294\n",
      "Deck            299\n",
      "Cabin_Number    299\n",
      "Side            299\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the combined dataset after KNN imputation and feature engineering\n",
    "print(\"Missing values in the combined dataset after KNN Imputation and feature engineering:\")\n",
    "print(combined_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "993397d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T13:26:16.723887Z",
     "iopub.status.busy": "2024-08-21T13:26:16.723486Z",
     "iopub.status.idle": "2024-08-21T13:26:16.753178Z",
     "shell.execute_reply": "2024-08-21T13:26:16.752044Z"
    },
    "papermill": {
     "duration": 0.037087,
     "end_time": "2024-08-21T13:26:16.755739",
     "exception": false,
     "start_time": "2024-08-21T13:26:16.718652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after filling categorical columns:\n",
      "PassengerId     0\n",
      "HomePlanet      0\n",
      "CryoSleep       0\n",
      "Destination     0\n",
      "Age             0\n",
      "VIP             0\n",
      "RoomService     0\n",
      "FoodCourt       0\n",
      "ShoppingMall    0\n",
      "Spa             0\n",
      "VRDeck          0\n",
      "Name            0\n",
      "Deck            0\n",
      "Cabin_Number    0\n",
      "Side            0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/3717679310.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_df['Deck'].fillna('U', inplace=True)\n",
      "/tmp/ipykernel_18/3717679310.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_df['Cabin_Number'].fillna(-1, inplace=True)\n",
      "/tmp/ipykernel_18/3717679310.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_df['Side'].fillna('U', inplace=True)\n",
      "/tmp/ipykernel_18/3717679310.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_df['HomePlanet'].fillna('U', inplace=True)\n",
      "/tmp/ipykernel_18/3717679310.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_df['Destination'].fillna('U', inplace=True)\n",
      "/tmp/ipykernel_18/3717679310.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_df['VIP'].fillna('U', inplace=True)\n",
      "/tmp/ipykernel_18/3717679310.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_df['CryoSleep'].fillna('U', inplace=True)\n",
      "/tmp/ipykernel_18/3717679310.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_df['Name'].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Filling missing values in Deck, Cabin_Number, Side with \"U\" and -1 respectively\n",
    "combined_df['Deck'].fillna('U', inplace=True)\n",
    "combined_df['Cabin_Number'].fillna(-1, inplace=True)\n",
    "combined_df['Side'].fillna('U', inplace=True)\n",
    "\n",
    "# Filling missing values in HomePlanet, Destination, VIP, and CryoSleep with \"U\"\n",
    "combined_df['HomePlanet'].fillna('U', inplace=True)\n",
    "combined_df['Destination'].fillna('U', inplace=True)\n",
    "combined_df['VIP'].fillna('U', inplace=True)\n",
    "combined_df['CryoSleep'].fillna('U', inplace=True)\n",
    "\n",
    "# Handling the Name column - optional, depending on its utility\n",
    "combined_df['Name'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Verify that there are no more missing values\n",
    "print(\"Missing values after filling categorical columns:\")\n",
    "print(combined_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f10cd44c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T13:26:16.766271Z",
     "iopub.status.busy": "2024-08-21T13:26:16.765134Z",
     "iopub.status.idle": "2024-08-21T13:26:16.803320Z",
     "shell.execute_reply": "2024-08-21T13:26:16.802026Z"
    },
    "papermill": {
     "duration": 0.046048,
     "end_time": "2024-08-21T13:26:16.805843",
     "exception": false,
     "start_time": "2024-08-21T13:26:16.759795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after One-Hot Encoding:\n",
      "    Age  RoomService  FoodCourt  ShoppingMall     Spa  VRDeck Cabin_Number  \\\n",
      "0  39.0          0.0        0.0           0.0     0.0     0.0            0   \n",
      "1  24.0        109.0        9.0          25.0   549.0    44.0            0   \n",
      "2  58.0         43.0     3576.0           0.0  6715.0    49.0            0   \n",
      "3  33.0          0.0     1283.0         371.0  3329.0   193.0            0   \n",
      "4  16.0        303.0       70.0         151.0   565.0     2.0            1   \n",
      "\n",
      "   HomePlanet_Europa  HomePlanet_Mars  HomePlanet_U  ...  Deck_B  Deck_C  \\\n",
      "0               True            False         False  ...    True   False   \n",
      "1              False            False         False  ...   False   False   \n",
      "2               True            False         False  ...   False   False   \n",
      "3               True            False         False  ...   False   False   \n",
      "4              False            False         False  ...   False   False   \n",
      "\n",
      "   Deck_D  Deck_E  Deck_F  Deck_G  Deck_T  Deck_U  Side_S  Side_U  \n",
      "0   False   False   False   False   False   False   False   False  \n",
      "1   False   False    True   False   False   False    True   False  \n",
      "2   False   False   False   False   False   False    True   False  \n",
      "3   False   False   False   False   False   False    True   False  \n",
      "4   False   False    True   False   False   False    True   False  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply One-Hot Encoding to categorical columns\n",
    "categorical_columns = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Deck', 'Side']\n",
    "\n",
    "# Use pandas get_dummies to create one-hot encoded columns\n",
    "combined_df_encoded = pd.get_dummies(combined_df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Optional: Drop the 'Name' and 'PassengerId' columns if they are not needed for the model\n",
    "combined_df_encoded.drop(columns=['Name', 'PassengerId'], inplace=True, errors='ignore')\n",
    "\n",
    "# Check the new dataframe with encoded categorical variables\n",
    "print(\"DataFrame after One-Hot Encoding:\")\n",
    "print(combined_df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4dc46e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T13:26:16.816592Z",
     "iopub.status.busy": "2024-08-21T13:26:16.815526Z",
     "iopub.status.idle": "2024-08-21T13:26:16.829800Z",
     "shell.execute_reply": "2024-08-21T13:26:16.828786Z"
    },
    "papermill": {
     "duration": 0.022295,
     "end_time": "2024-08-21T13:26:16.832408",
     "exception": false,
     "start_time": "2024-08-21T13:26:16.810113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after converting boolean columns to integers:\n",
      "   Age  RoomService  FoodCourt  ShoppingMall   Spa  VRDeck  Cabin_Number  \\\n",
      "0   39            0          0             0     0       0             0   \n",
      "1   24          109          9            25   549      44             0   \n",
      "2   58           43       3576             0  6715      49             0   \n",
      "3   33            0       1283           371  3329     193             0   \n",
      "4   16          303         70           151   565       2             1   \n",
      "\n",
      "   HomePlanet_Europa  HomePlanet_Mars  HomePlanet_U  ...  Deck_B  Deck_C  \\\n",
      "0                  1                0             0  ...       1       0   \n",
      "1                  0                0             0  ...       0       0   \n",
      "2                  1                0             0  ...       0       0   \n",
      "3                  1                0             0  ...       0       0   \n",
      "4                  0                0             0  ...       0       0   \n",
      "\n",
      "   Deck_D  Deck_E  Deck_F  Deck_G  Deck_T  Deck_U  Side_S  Side_U  \n",
      "0       0       0       0       0       0       0       0       0  \n",
      "1       0       0       1       0       0       0       1       0  \n",
      "2       0       0       0       0       0       0       1       0  \n",
      "3       0       0       0       0       0       0       1       0  \n",
      "4       0       0       1       0       0       0       1       0  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert boolean columns to integers (0 and 1)\n",
    "combined_df_encoded = combined_df_encoded.astype(int)\n",
    "\n",
    "# Verify the changes\n",
    "print(\"DataFrame after converting boolean columns to integers:\")\n",
    "print(combined_df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffec3b84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T13:26:16.842535Z",
     "iopub.status.busy": "2024-08-21T13:26:16.842154Z",
     "iopub.status.idle": "2024-08-21T13:26:16.867039Z",
     "shell.execute_reply": "2024-08-21T13:26:16.865195Z"
    },
    "papermill": {
     "duration": 0.033015,
     "end_time": "2024-08-21T13:26:16.869539",
     "exception": false,
     "start_time": "2024-08-21T13:26:16.836524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training dataset:\n",
      "   Age  RoomService  FoodCourt  ShoppingMall   Spa  VRDeck  Cabin_Number  \\\n",
      "0   39            0          0             0     0       0             0   \n",
      "1   24          109          9            25   549      44             0   \n",
      "2   58           43       3576             0  6715      49             0   \n",
      "3   33            0       1283           371  3329     193             0   \n",
      "4   16          303         70           151   565       2             1   \n",
      "\n",
      "   HomePlanet_Europa  HomePlanet_Mars  HomePlanet_U  ...  Deck_C  Deck_D  \\\n",
      "0                  1                0             0  ...       0       0   \n",
      "1                  0                0             0  ...       0       0   \n",
      "2                  1                0             0  ...       0       0   \n",
      "3                  1                0             0  ...       0       0   \n",
      "4                  0                0             0  ...       0       0   \n",
      "\n",
      "   Deck_E  Deck_F  Deck_G  Deck_T  Deck_U  Side_S  Side_U  Transported  \n",
      "0       0       0       0       0       0       0       0        False  \n",
      "1       0       1       0       0       0       1       0         True  \n",
      "2       0       0       0       0       0       1       0        False  \n",
      "3       0       0       0       0       0       1       0        False  \n",
      "4       0       1       0       0       0       1       0         True  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "\n",
      "Final test dataset:\n",
      "      Age  RoomService  FoodCourt  ShoppingMall   Spa  VRDeck  Cabin_Number  \\\n",
      "8693   27            0          0             0     0       0             3   \n",
      "8694   19            0          9             0  2823       0             4   \n",
      "8695   31            0          0             0     0       0             0   \n",
      "8696   38            0       6652             0   181     585             1   \n",
      "8697   20           10          0           635     0       0             5   \n",
      "\n",
      "      HomePlanet_Europa  HomePlanet_Mars  HomePlanet_U  ...  Deck_B  Deck_C  \\\n",
      "8693                  0                0             0  ...       0       0   \n",
      "8694                  0                0             0  ...       0       0   \n",
      "8695                  1                0             0  ...       0       1   \n",
      "8696                  1                0             0  ...       0       1   \n",
      "8697                  0                0             0  ...       0       0   \n",
      "\n",
      "      Deck_D  Deck_E  Deck_F  Deck_G  Deck_T  Deck_U  Side_S  Side_U  \n",
      "8693       0       0       0       1       0       0       1       0  \n",
      "8694       0       0       1       0       0       0       1       0  \n",
      "8695       0       0       0       0       0       0       1       0  \n",
      "8696       0       0       0       0       0       0       1       0  \n",
      "8697       0       0       1       0       0       0       1       0  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# Split the combined data back into train and test datasets\n",
    "train_df_final = combined_df_encoded.iloc[:len(train_df), :].copy()\n",
    "test_df_final = combined_df_encoded.iloc[len(train_df):, :].copy()\n",
    "\n",
    "# Reattach the 'Transported' column back to the train dataset\n",
    "train_df_final['Transported'] = train_df['Transported'].values\n",
    "\n",
    "# Verify the final train and test datasets\n",
    "print(\"Final training dataset:\")\n",
    "print(train_df_final.head())\n",
    "\n",
    "print(\"\\nFinal test dataset:\")\n",
    "print(test_df_final.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b00f9682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T13:26:16.879973Z",
     "iopub.status.busy": "2024-08-21T13:26:16.879601Z",
     "iopub.status.idle": "2024-08-21T13:26:17.328184Z",
     "shell.execute_reply": "2024-08-21T13:26:17.326891Z"
    },
    "papermill": {
     "duration": 0.456578,
     "end_time": "2024-08-21T13:26:17.330528",
     "exception": false,
     "start_time": "2024-08-21T13:26:16.873950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7872\n",
      "Submission file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: Prepare the data\n",
    "X = train_df_final.drop(columns=['Transported'])\n",
    "y = train_df_final['Transported'].astype(int)  # Ensure that 'Transported' is binary (0 or 1)\n",
    "\n",
    "# Step 2: Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Train the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "y_pred = xgb_model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Step 5: Make predictions on the test set\n",
    "test_predictions = xgb_model.predict(test_df_final)\n",
    "\n",
    "# Step 6: Prepare the submission\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Transported': test_predictions.astype(bool)  # Convert to boolean as expected by Kaggle\n",
    "})\n",
    "\n",
    "# Export submission to CSV\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file created successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 3220602,
     "sourceId": 34377,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.674536,
   "end_time": "2024-08-21T13:26:17.957221",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-21T13:26:10.282685",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
